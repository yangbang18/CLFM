{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ce75e1-9b81-49ee-ad32-e816a9d95d00",
   "metadata": {},
   "source": [
    "# 1. XM3600\n",
    "```\r\n",
    "@inproceedings{thapliyal2022XM3600,\r\n",
    "  title = {Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset},\r\n",
    "  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},\r\n",
    "  author = {Thapliyal, Ashish V. and Pont Tuset, Jordi and Chen, Xi and Soricut, Radu},\r\n",
    "  year = {2022},\r\n",
    "  pages = {715--729}\r\n",
    "}\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36684627-7e00-4631-aa35-7b4dc03786ad",
   "metadata": {},
   "source": [
    "## 1.1 Official Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ee3a11-c92b-4a48-9473-32319389c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-25 18:10:52--  https://google.github.io/crossmodal-3600/web-data/captions.zip\n",
      "Resolving google.github.io (google.github.io)... 2606:50c0:8002::153, 2606:50c0:8003::153, 2606:50c0:8000::153, ...\n",
      "Connecting to google.github.io (google.github.io)|2606:50c0:8002::153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16778794 (16M) [application/zip]\n",
      "Saving to: ‘captions.zip’\n",
      "\n",
      "captions.zip        100%[===================>]  16.00M  9.32MB/s    in 1.7s    \n",
      "\n",
      "2023-12-25 18:10:55 (9.32 MB/s) - ‘captions.zip’ saved [16778794/16778794]\n",
      "\n",
      "Archive:  captions.zip\n",
      "  inflating: captions.jsonl          \n"
     ]
    }
   ],
   "source": [
    "!wget -c https://google.github.io/crossmodal-3600/web-data/captions.zip --no-check-certificate\n",
    "!unzip captions.zip\n",
    "!rm captions.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef92b847-df4f-46d3-abd2-8d36eb026870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -c https://open-images-dataset.s3.amazonaws.com/crossmodal-3600/images.tgz --no-check-certificate\n",
    "# !mkdir XM3600\n",
    "# !tar -xvzf images.tgz -C XM3600\n",
    "# !rm images.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e83d1c-0cef-4079-8a3b-c20a6dd3a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAVE_PATH = './annotations/xm3600'\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3605adc5-c971-45a8-b73e-9d4655b0c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('captions.jsonl').read().strip().split('\\n')\n",
    "data = {i: eval(line) for i, line in enumerate(lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777bf4be-6812-48d1-9261-ce9b5af15f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image/key', 'image/locale', 'ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'hi', 'hr', 'hu', 'id', 'it', 'he', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba97be2-868d-4c35-9288-ec180047ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for key in data[0].keys():\n",
    "    if 'image' not in key:\n",
    "        save_path = os.path.join(SAVE_PATH, key)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        test_data = []\n",
    "        for i in range(len(data)):\n",
    "            item = {'image': data[i]['image/key'] + '.jpg', 'image/locale': data[i]['image/locale'], 'caption': data[i][key]['caption'], 'image_id': i}\n",
    "            test_data.append(item)\n",
    "        \n",
    "        with open(os.path.join(save_path, 'test.json'), 'w') as wf:\n",
    "            json.dump(test_data, wf)\n",
    "        \n",
    "        for caption_key, name in zip(['caption', 'caption/tokenized/lowercase'], ['test_gt.json', 'test_tokenized_gt.json']):\n",
    "            gt = {\n",
    "                'annotations': [],\n",
    "                'images': [],\n",
    "            }\n",
    "\n",
    "            caption_id = 0\n",
    "            for item in test_data:\n",
    "                assert isinstance(item['caption'], (list, tuple))\n",
    "                image_id = item['image_id']\n",
    "                for caption in data[image_id][key][caption_key]:\n",
    "                    item = dict(\n",
    "                        image_id=image_id,\n",
    "                        caption=caption,\n",
    "                        id=caption_id,\n",
    "                    )\n",
    "                    caption_id += 1\n",
    "                    gt['annotations'].append(item)\n",
    "                gt['images'].append({'id': image_id})\n",
    "                        \n",
    "            with open(os.path.join(save_path, name), 'w') as wf:\n",
    "                json.dump(gt, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3d501d-3897-4cd2-b2cf-5470e0f0bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm captions.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf6871-616a-4f01-ac4a-84565409603d",
   "metadata": {},
   "source": [
    "## 1.2 Translating XM3600's annotations into English for the translate-test evaluation\n",
    "Here are the steps:\n",
    "1. put the test captions in, e.g., `annotations/xm3600/ar/test.json`, into a `.docx` file line by line (refer to 1.2.1)\n",
    "2. get the translated results of the 1st step's file via [Google Translator](https://translate.google.com)\n",
    "3. convert the 2nd step's results to, e.g., `annotations/xm3600/translated_to_en/ar/test.json` (refer to 1.2.3)\n",
    "\n",
    "**Note:** `annotations/xm3600/en/test.json` is identical to `annotations/xm3600/translated_to_en/en/test.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0641a-ba21-43f4-907c-9e625f510d61",
   "metadata": {},
   "source": [
    "### 1.2.1 `annotations/xm3600/{lang}/test.json` --> `dummy_xm3600/{lang}.docx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e33a02f9-68ae-4704-a0ae-7c7e9b2c4161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/bangyang/anaconda3/envs/clfm/lib/python3.8/site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions in /home/bangyang/anaconda3/envs/clfm/lib/python3.8/site-packages (from python-docx) (4.8.0)\n",
      "Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m718.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa7cd9fd-8b28-402e-95a7-174106ea281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar 7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▎                                                                                                                                                       | 1/36 [00:01<00:59,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn 3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▋                                                                                                                                                   | 2/36 [00:02<00:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs 7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████                                                                                                                                               | 3/36 [00:03<00:34,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da 7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████▎                                                                                                                                          | 4/36 [00:04<00:40,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de 8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████████████▋                                                                                                                                      | 5/36 [00:06<00:46,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el 7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████████████                                                                                                                                  | 6/36 [00:08<00:41,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████████████▎                                                                                                                             | 7/36 [00:09<00:37,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es 8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▋                                                                                                                         | 8/36 [00:10<00:37,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa 7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████                                                                                                                     | 9/36 [00:11<00:35,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fi 7127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████████████████                                                                                                                | 10/36 [00:12<00:32,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fil 7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████████████████████████▎                                                                                                           | 11/36 [00:14<00:30,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr 8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████████████████████████▋                                                                                                       | 12/36 [00:15<00:31,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████████████████▉                                                                                                   | 13/36 [00:16<00:29,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi 8503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████████████████████████████▎                                                                                              | 14/36 [00:18<00:29,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr 7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████████████████████████████▌                                                                                          | 15/36 [00:19<00:27,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hu 7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████▉                                                                                      | 16/36 [00:20<00:24,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████████████████████████████████████▏                                                                                 | 17/36 [00:21<00:22,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 18/36 [00:23<00:23,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja 7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████████████████████████████████████▊                                                                         | 19/36 [00:24<00:20,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko 7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████████████████████████████                                                                     | 20/36 [00:25<00:19,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mi 4732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 21/36 [00:26<00:16,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl 8059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 22/36 [00:28<00:18,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 7213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 23/36 [00:29<00:16,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl 7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                   | 24/36 [00:30<00:14,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt 7243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 25/36 [00:31<00:12,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quz 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 26/36 [00:32<00:11,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro 7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 27/36 [00:33<00:10,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 28/36 [00:35<00:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv 7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 29/36 [00:36<00:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sw 7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 30/36 [00:37<00:07,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 31/36 [00:38<00:06,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 32/36 [00:39<00:04,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr 7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 33/36 [00:41<00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uk 7215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 34/36 [00:42<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi 7350\n",
      "Dòngchâm ngôn chống tư bản gắn trên tường có khung được kết từ rất nhiều mảnh thẻ Visa vụn, bên dưới có mã QR\n",
      "Dòng châm ngôn chống tư bản gắn trên tường có khung được kết từ rất nhiều mảnh thẻ Visa vụn, bên dưới có mã QR\n",
      "Chiếc bànxếp chân sắt phủ tấm trải viền cờ mỹ, trên mặt bàn có 2 hộp bánh rán vòng, dưới chân có lốc nước khoáng và thùng màu trắng, bàn đặt trong căn phòng có sàn màu trắng\n",
      "Chiếc bàn xếp chân sắt phủ tấm trải viền cờ mỹ, trên mặt bàn có 2 hộp bánh rán vòng, dưới chân có lốc nước khoáng và thùng màu trắng, bàn đặt trong căn phòng có sàn màu trắng\n",
      "\bnam thanh niên trẻ mặc áo phông đỏ, đeo kính, tóc húi cua\n",
      "nam thanh niên trẻ mặc áo phông đỏ, đeo kính, tóc húi cua\n",
      "Món chân gà rán phủ sốt cay ngon tuyệtbày trên đĩa trắng\n",
      "Món chân gà rán phủ sốt cay ngon tuyệt bày trên đĩa trắng\n",
      "\bnam doanh nhân da màu trung niên tươi cười bên bức tường có chữ Ushahidi\n",
      "nam doanh nhân da màu trung niên tươi cười bên bức tường có chữ Ushahidi\n",
      "ĐườngThống nhất tại Sài Gòn khá đông đúc ô tô chờ đèn đỏ năm 1966-1967\n",
      "Đường Thống nhất tại Sài Gòn khá đông đúc ô tô chờ đèn đỏ năm 1966-1967\n",
      "Túi hàng màu trắng bằng nilon i nhãn inateck\n",
      "Túi hàng màu trắng bằng nilon in nhãn inateck\n",
      "Cận cảnhmón đậu nành luộc edamame ngon lành trên mẹt tre\n",
      "Cận cảnh món đậu nành luộc edamame ngon lành trên mẹt tre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 35/36 [00:43<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh 7174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:44<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from  tqdm import tqdm\n",
    "from docx import Document\n",
    "\n",
    "annotations_root = \"annotations/xm3600\"\n",
    "save_root = 'dummy_xm3600'\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "fn = 'test.json'\n",
    "\n",
    "langs = ['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']\n",
    "\n",
    "for lang in tqdm(langs):\n",
    "    save_path = os.path.join(save_root, f'{lang}.docx')\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "    json_data = json.load(open(os.path.join(annotations_root, lang, fn), 'r', encoding='utf8'))\n",
    "    captions = [caption.strip() for item in json_data for caption in item['caption']]\n",
    "    print(lang, len(captions))\n",
    "\n",
    "    doc = Document()\n",
    "    for caption in captions:\n",
    "        try:\n",
    "            doc.add_paragraph(caption)\n",
    "        except:\n",
    "            print(caption)\n",
    "            caption = re.sub(u\"[\\\\x00-\\\\x08\\\\x0b\\\\x0e-\\\\x1f\\\\x7f]\", \"\", caption)\n",
    "            print(caption)\n",
    "            doc.add_paragraph(caption)\n",
    "        \n",
    "    doc.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc5f997-719e-41e1-9a09-bfb9a88835ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在山里中站着两只鸡，一只黄色另一只黑黄色，它们俩站着看向同一个方向\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "doc = Document(os.path.join(save_root, 'zh.docx'))\n",
    "for p in doc.paragraphs:\n",
    "    print(p.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207f11e-794f-49a7-854e-4f52275185e4",
   "metadata": {},
   "source": [
    "### 1.2.2 Translate `dummy_xm3600/{lang}.docx` into English by yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21847e0f-1b5c-4145-8de4-5b2fffce4115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar \t Rooster and chick on the ground\n",
      "bn \t There are two brown and black colored chickens in the Jungle Madha\n",
      "cs \t Rooster and hen in the grass\n",
      "da \t A brown hen and a multicolored rooster in the forest floor\n",
      "de \t A hen and a hen in the stony garden in the grass.\n",
      "el \t Rooster and hen\n",
      "en \t A rooster and hens surrounded by green leaves.\n",
      "es \t A rooster and a hen among rocks and grass\n",
      "fa \t Rooster and chicken in the garden on a clear day\n",
      "fi \t Two chickens and a rooster walking in the forest\n",
      "fil \t Two roosters and another chicken with incomplete picture\n",
      "fr \t A hen and a rooster in the woods\n",
      "he \t Chickens walk on the ground with green vegetation around.\n",
      "hi \t view of two chickens among small plants on the ground\n",
      "hr \t A hen with brown feathers and a rooster with black and brown feathers in nature\n",
      "hu \t Rooster and hen.\n",
      "id \t 2 chickens nestling in an open garden area among the weeds\n",
      "it \t Roosters in the wild, natural environment, dry leaves, weeds, uneven ground\n",
      "ja \t Two roosters walking in the grass\n",
      "ko \t Two chickens standing on a stone on a mountain road with lots of fallen leaves and weeds\n",
      "mi \t There are two tame chickens.\n",
      "nl \t Two roosters\n",
      "no \t Rooster and hens standing on the grassy ground\n",
      "pl \t Rooster and hen walking free\n",
      "pt \t Rooster and hen walking in the bush\n",
      "quz \t Two ch ́umpi chickens are purring\n",
      "ro \t Hen and rooster in nature with greenery and stones\n",
      "ru \t Bright rooster and his brown hens in the park\n",
      "sv \t Rooster and hen\n",
      "sw \t Picture of traditional rooster and local chicken\n",
      "te \t Roaming between the plants is a hen Petta and Punju.\n",
      "th \t Three chickens are walking on a hill with rocks and grass on a sunny day.\n",
      "tr \t Chicken and rooster in the garden\n",
      "uk \t In the foreground is a brown speckled hen, further - a brown-black rooster, the photo is not of very high quality\n",
      "vi \t A rooster and a hen are foraging in the garden\n",
      "zh \t Two chickens are standing in the middle of the mountain, one is yellow and the other is black and yellow, they both stand and look in the same direction\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "save_root = 'dummy_xm3600'\n",
    "langs = ['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']\n",
    "for lang in langs:\n",
    "    doc = Document(os.path.join(save_root, f'{lang}.docx'))\n",
    "    for p in doc.paragraphs:\n",
    "        print(lang, '\\t', p.text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26b442-d7e6-4f71-a1c4-1c38e01b0b11",
   "metadata": {},
   "source": [
    "### 1.2.3 `dummy_xm3600/{lang}.docx` --> `annotations/xm3600/translated_to_en/{lang}/test.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0b08932-daf8-43c3-ba0a-d64adc1a4527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 82062.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from  tqdm import tqdm\n",
    "from docx import Document\n",
    "\n",
    "annotations_root = 'annotations/xm3600'\n",
    "save_root = os.path.join(annotations_root, 'translated_to_en')\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "read_root = 'dummy_xm3600'\n",
    "fn = 'test.json'\n",
    "\n",
    "langs = ['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']\n",
    "\n",
    "for lang in tqdm(langs):\n",
    "    this_save_path = os.path.join(save_root, lang, fn)\n",
    "    if os.path.exists(this_save_path):\n",
    "        continue\n",
    "\n",
    "    json_data = json.load(open(os.path.join(annotations_root, lang, fn), 'r', encoding='utf8'))\n",
    "\n",
    "    if lang == 'en':\n",
    "        save_data = json_data\n",
    "    else:\n",
    "        save_data = []\n",
    "        read_path = f'{read_root}/{lang}.docx'\n",
    "        captions = [p.text for p in Document(read_path).paragraphs]\n",
    "        captions = [c.strip() for c in captions if c.strip()]\n",
    "        caption_idx = 0\n",
    "        for item in json_data:\n",
    "            num_captions = len(item['caption'])\n",
    "            new_item = copy.deepcopy(item)\n",
    "            new_item['caption'] = captions[caption_idx:caption_idx+num_captions]\n",
    "            save_data.append(new_item)\n",
    "            caption_idx += num_captions\n",
    "\n",
    "        assert caption_idx == len(captions), f'{lang} {caption_idx} {len(captions)}'\n",
    "    assert len(save_data) == len(json_data)\n",
    "\n",
    "    os.makedirs(os.path.dirname(this_save_path), exist_ok=True)\n",
    "    with open(this_save_path, 'w') as wf:\n",
    "        json.dump(save_data, wf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d4c2bbe-5314-40cf-9fcc-aa2db7fe06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r dummy_xm3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977e1d9-9479-4654-8d7e-143d6a627d1d",
   "metadata": {},
   "source": [
    "# 2. MSCOCO (Karpathy's splits)\n",
    "\n",
    "```bibtex\n",
    "@misc{chen2015MSCOCO,\n",
    "  title = {Microsoft COCO Captions: Data Collection and Evaluation Server},\n",
    "  author = {Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Dollar, Piotr and Zitnick, C. Lawrence},\n",
    "  year = {2015},\n",
    "  number = {arXiv:1504.00325},\n",
    "  eprint = {1504.00325},\n",
    "  doi = {10.48550/arXiv.1504.00325},\n",
    "  archiveprefix = {arxiv}\n",
    "}\r\n",
    "@inproceedings{karpathy2015deep,\r\n",
    "  title={Deep visual-semantic alignments for generating image descriptions},\r\n",
    "  author={Karpathy, Andrej and Fei-Fei, Li},\r\n",
    "  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\r\n",
    "  pages={3128--3137},\r\n",
    "  ye015},ar={2015}``\r\n",
    "}\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd7971-8ac8-4a9b-959e-444dc152df8f",
   "metadata": {},
   "source": [
    "## 2.1 Official Annotations\n",
    "\n",
    "Please refer to [yangbang18/ZeroNLG/data/prepare_text_data.ipynb](https://github.com/yangbang18/ZeroNLG/blob/master/data/prepare_text_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823dad5f-88e3-40f4-ad67-c2e0c4ed515c",
   "metadata": {},
   "source": [
    "## 2.2 Translating MSCOCO's English annotations into 36 languages\n",
    "Here are the steps:\n",
    "1. put the val and test captions into `.docx` files line by line respectively (refer to 2.2.1)\n",
    "2. get the translated results of the 1st step's file via [Google Translator](https://translate.google.com)\n",
    "3. convert the 2nd step's results to, e.g., `annotations/coco/translated/ar/val.json` and `annotations/coco/translated/ar/test.json` (refer to 2.2.3)\n",
    "\n",
    "**Note:** `annotations/coco/en/*` is identical to `annotations/coco/translated/en/*`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226197fc-d48a-4298-b2e2-2845b1264a60",
   "metadata": {},
   "source": [
    "### 2.2.1 `annotations/coco/en/val.json` --> `dummy_val/coco_en.docx` && `annotations/coco/en/test.json` --> `dummy_test/coco_en.docx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea68dc9-3f23-4c3f-b94e-836075910cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 25010 ['A child holding a flowered umbrella and petting a yak.', 'A young man holding an umbrella next to a herd of cattle.', 'a young boy barefoot holding an umbrella touching the horn of a cow']\n",
      "test 25010 ['A man with a red helmet on a small moped on a dirt road.', 'Man riding a motor bike on a dirt road on the countryside.', 'A man riding on the back of a motorcycle.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "\n",
    "annotations_root = \"annotations/coco\"\n",
    "save_root_format = 'dummy_{}'\n",
    "\n",
    "for mode in ['val', 'test']:\n",
    "    save_root = save_root_format.format(mode)\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    save_path = os.path.join(save_root, 'coco_en.docx')\n",
    "    \n",
    "    json_data = json.load(open(os.path.join(annotations_root, 'en', f'{mode}.json')))\n",
    "    captions = [caption.strip() for item in json_data for caption in item['caption']]\n",
    "    print(mode, len(captions), captions[:3])\n",
    "\n",
    "    doc = Document()\n",
    "    for caption in captions:\n",
    "        doc.add_paragraph(caption)\n",
    "    doc.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32816809-4fc8-456b-9311-96b114573823",
   "metadata": {},
   "source": [
    "### 2.2.2 Translate `dummy_val/coco_en.docx` and `dummy_test/coco_en.docx` into other 35 languages by yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5fd085c-ee70-4190-b77c-514340c61346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar \t طفل يحمل مظلة مزهرة ويأكل ثورًا.\n",
      "bn \t একটি শিশু একটি ফুলের ছাতা ধরে একটি ইয়াক পোষাচ্ছে।\n",
      "cs \t Dítě drží květovaný deštník a hladí jaka.\n",
      "da \t Et barn holder en blomstret paraply og klapper en yak.\n",
      "de \t Ein Kind hält einen geblümten Regenschirm und streichelt ein Yak.\n",
      "el \t Ένα παιδί που κρατά μια ανθισμένη ομπρέλα και χαϊδεύει ένα γιακ.\n",
      "en \t A child holding a flowered umbrella and petting a yak.\n",
      "es \t Un niño sosteniendo un paraguas floreado y acariciando un yak.\n",
      "fa \t کودکی که چتر گلدار را در دست گرفته و سگی را نوازش می کند.\n",
      "fi \t Lapsi pitelee kukkaista sateenvarjoa ja silittää jakkia.\n",
      "fil \t Isang bata na may hawak na bulaklak na payong at hinahaplos ang isang yak.\n",
      "fr \t Un enfant tenant un parapluie fleuri et caressant un yak.\n",
      "he \t ילד מחזיק מטריה פרחונית ומלטף יאק.\n",
      "hi \t फूल छाता लिए एक बच्चा और याक को सहला रहा है।\n",
      "hr \t Dijete drži kišobran s cvjetovima i mazi jaka.\n",
      "hu \t Egy gyerek, aki virágos esernyőt tart, és egy jakot simogat.\n",
      "id \t Seorang anak memegang payung berbunga dan mengelus yak.\n",
      "it \t Un bambino che tiene un ombrello fiorito e accarezza uno yak.\n",
      "ja \t 花柄の傘をさし、ヤクを撫でる子供。\n",
      "ko \t 꽃 우산을 들고 야크를 쓰다듬는 아이.\n",
      "mi \t He tamaiti e mau ana i te marara pua me te mirimiri i te yak.\n",
      "nl \t Een kind dat een gebloemde paraplu vasthoudt en een jak aait.\n",
      "no \t Et barn som holder en blomstret paraply og klapper en yak.\n",
      "pl \t Dziecko trzymające ukwiecony parasol i głaszczące jaka.\n",
      "pt \t Uma criança segurando um guarda-chuva florido e acariciando um iaque.\n",
      "quz \t Wawa t’ikayuq paraguasta hap’ispa yakuta abrazaspa.\n",
      "ro \t Un copil care ține o umbrelă înflorată și mângâie un iac.\n",
      "ru \t Ребенок держит зонтик с цветами и гладит яка.\n",
      "sv \t Ett barn som håller ett blommigt paraply och klappar en jak.\n",
      "sw \t Mtoto akiwa ameshika mwavuli wenye maua na kubembeleza yak.\n",
      "te \t ఒక పిల్లవాడు పూల గొడుగు పట్టుకుని, యాక్‌ను పెంపొందిస్తున్నాడు.\n",
      "th \t เด็กถือร่มดอกไม้และลูบจามรี\n",
      "tr \t Çiçekli bir şemsiye tutan ve bir yakı okşayan bir çocuk.\n",
      "uk \t Дитина тримає квітчасту парасольку та гладить яка.\n",
      "vi \t Một đứa trẻ cầm chiếc ô hoa và vuốt ve một con bò Tây Tạng.\n",
      "zh \t 一个拿着花伞抚摸着牦牛的孩子。\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "save_root = 'dummy_val'\n",
    "langs = ['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']\n",
    "for lang in langs:\n",
    "    doc = Document(os.path.join(save_root, f'coco_{lang}.docx'))\n",
    "    for p in doc.paragraphs:\n",
    "        print(lang, '\\t', p.text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "468d5a1c-02ce-4e6b-82db-040097126d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar \t رجل يرتدي خوذة حمراء على دراجة بخارية صغيرة على طريق ترابي.\n",
      "bn \t একটি কাঁচা রাস্তায় একটি ছোট মোপেডে লাল হেলমেট পরা একজন ব্যক্তি।\n",
      "cs \t Muž s červenou helmou na malém mopedu na polní cestě.\n",
      "da \t En mand med rød hjelm på en lille knallert på en grusvej.\n",
      "de \t Ein Mann mit rotem Helm auf einem kleinen Moped auf einer unbefestigten Straße.\n",
      "el \t Ένας άντρας με ένα κόκκινο κράνος σε ένα μικρό μοτοποδήλατο σε έναν χωματόδρομο.\n",
      "en \t A man with a red helmet on a small moped on a dirt road.\n",
      "es \t Un hombre con casco rojo en un pequeño ciclomotor en un camino de tierra.\n",
      "fa \t مردی با کلاه ایمنی قرمز روی یک موپد کوچک در جاده خاکی.\n",
      "fi \t Mies punaisella kypärällä pienellä mopolla hiekkatiellä.\n",
      "fil \t Isang lalaking may pulang helmet sa isang maliit na moped sa isang maruming kalsada.\n",
      "fr \t Un homme avec un casque rouge sur un petit cyclomoteur sur un chemin de terre.\n",
      "he \t אדם עם קסדה אדומה על טוסטוס קטן בדרך עפר.\n",
      "hi \t गंदगी भरी सड़क पर छोटी मोपेड पर लाल हेलमेट पहने एक आदमी।\n",
      "hr \t Čovjek s crvenom kacigom na malom mopedu na makadamskoj cesti.\n",
      "hu \t Egy piros sisakos férfi egy kis mopeden egy földúton.\n",
      "id \t Seorang pria dengan helm merah di moped kecil di jalan tanah.\n",
      "it \t Un uomo con un casco rosso su un piccolo ciclomotore su una strada sterrata.\n",
      "ja \t 未舗装の道路を小型の原付バイクに乗って赤いヘルメットをかぶった男性。\n",
      "ko \t 비포장 도로에서 작은 오토바이에 빨간 헬멧을 쓴 남자.\n",
      "mi \t He tangata he potae whero i runga i te moped iti i runga i te huarahi paru.\n",
      "nl \t Een man met een rode helm op een kleine brommer op een onverharde weg.\n",
      "no \t En mann med rød hjelm på en liten moped på en grusvei.\n",
      "pl \t Mężczyzna z czerwonym hełmem na małym motorowerze na polnej drodze.\n",
      "pt \t Um homem com um capacete vermelho em um pequeno ciclomotor em uma estrada de terra.\n",
      "quz \t Allpa ñanpi uchuy ciclomotorpi puka cascoyuq runa.\n",
      "ro \t Un bărbat cu o cască roșie pe o mopedă mică pe un drum de pământ.\n",
      "ru \t Мужчина в красном шлеме на маленьком мопеде по грунтовой дороге.\n",
      "sv \t En man med röd hjälm på en liten moped på en grusväg.\n",
      "sw \t Mtu aliye na kofia nyekundu kwenye moped ndogo kwenye barabara ya uchafu.\n",
      "te \t మట్టి రోడ్డుపై చిన్న మోపెడ్‌పై ఎర్రటి హెల్మెట్‌తో ఉన్న వ్యక్తి.\n",
      "th \t ชายสวมหมวกกันน็อคสีแดงขี่มอเตอร์ไซค์คันเล็กๆ บนถนนลูกรัง\n",
      "tr \t Toprak yolda küçük bir moped üzerinde kırmızı kasklı bir adam.\n",
      "uk \t Чоловік у червоному шоломі на невеликому мопеді на ґрунтовій дорозі.\n",
      "vi \t Một người đàn ông với chiếc mũ bảo hiểm màu đỏ trên một chiếc xe gắn máy nhỏ trên con đường đất.\n",
      "zh \t 一名戴着红色头盔的男子骑着一辆小型轻便摩托车行驶在土路上。\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "save_root = 'dummy_test'\n",
    "langs = ['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']\n",
    "for lang in langs:\n",
    "    doc = Document(os.path.join(save_root, f'coco_{lang}.docx'))\n",
    "    for p in doc.paragraphs:\n",
    "        print(lang, '\\t', p.text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57aff42-8321-4806-8757-56feea01a017",
   "metadata": {},
   "source": [
    "### 2.2.3 `dummy_val/coco_{lang}.docx` --> `annotations/coco/translated/{lang}/val.json` && `dummy_test/coco_{lang}.docx` --> `annotations/coco/translated/{lang}/test.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaec7275-e324-43c3-ae3f-3ac743b77b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                     | 0/2 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 24999.16it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 20532.36it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 18.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from  tqdm import tqdm\n",
    "from docx import Document\n",
    "\n",
    "annotations_root = 'annotations/coco'\n",
    "save_root = os.path.join(annotations_root, 'translated')\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "read_path_format = 'dummy_{}/coco_{}.docx'\n",
    "\n",
    "langs = ['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']\n",
    "\n",
    "for mode in tqdm(['val', 'test']):\n",
    "    json_data = json.load(open(os.path.join(annotations_root, 'en', f'{mode}.json')))\n",
    "    gt_data = json.load(open(os.path.join(annotations_root, 'en', f'{mode}_gt.json')))\n",
    "    \n",
    "    for lang in tqdm(langs):\n",
    "        save_path = os.path.join(save_root, lang)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        path1 = os.path.join(save_path, f'{mode}.json')\n",
    "        path2 = os.path.join(save_path, f'{mode}_gt.json')\n",
    "        if os.path.exists(path1) and os.path.exists(path2):\n",
    "            continue\n",
    "        \n",
    "        if lang == 'en':\n",
    "            save_data = json_data\n",
    "            gt = gt_data\n",
    "        else:\n",
    "            save_data = []\n",
    "            read_path = read_path_format.format(mode, lang)\n",
    "            captions = [p.text for p in Document(read_path).paragraphs]\n",
    "            caption_idx = 0\n",
    "            caption_id = 0\n",
    "            gt = {\n",
    "                'annotations': [],\n",
    "                'images': [],\n",
    "            }\n",
    "            for item in json_data:\n",
    "                num_captions = len(item['caption'])\n",
    "                new_item = copy.deepcopy(item)\n",
    "                new_item['caption'] = captions[caption_idx:caption_idx+num_captions]\n",
    "                save_data.append(new_item)\n",
    "                caption_idx += num_captions\n",
    "    \n",
    "                image_id = item['image_id']\n",
    "                for caption in new_item['caption']:\n",
    "                    gt['annotations'].append(\n",
    "                        dict(\n",
    "                            image_id=image_id,\n",
    "                            caption=caption,\n",
    "                            id=caption_id,\n",
    "                    ))\n",
    "                    caption_id += 1\n",
    "                gt['images'].append({'id': image_id})\n",
    "        \n",
    "        if not os.path.exists(path1):\n",
    "            with open(path1, 'w') as wf:\n",
    "                json.dump(save_data, wf)\n",
    "    \n",
    "        if not os.path.exists(path2):\n",
    "            with open(path2, 'w') as wf:\n",
    "                json.dump(gt, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1134a340-8421-40a5-9515-cf86224dff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r dummy_val\n",
    "!rm -r dummy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97816a-40d7-4833-8da5-aa5de8da9078",
   "metadata": {},
   "source": [
    "## 2.3 Multilingual Corpora\n",
    "\n",
    "Similar to Section 2.2:\n",
    "1. put the train captions (`annotations/coco/en/train.json`) into a `.docx` file line by line\n",
    "2. get the translated results of the 1st step's file via [Google Translator](https://translate.google.com)\n",
    "3. convert the 2nd step's results to, e.g., `corpus/multilingual_coco/36langs/coco_en.tsv.gz` and `corpus/multilingual_coco/36langs/coco_en-zh.tsv.gz`\n",
    "\n",
    "**Note:** captions in `annotations/coco/en/train.json` are identical to `corpus/multilingual_coco/36langs/coco_en.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91bea308-3256-45ed-bcfb-1f85fd810eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566747\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_data = json.load(open(\"annotations/coco/en/train.json\"))\n",
    "json_captions = []\n",
    "for item in json_data:\n",
    "    json_captions.append(item['caption'].strip().replace('\\n', ' '))\n",
    "print(len(json_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d68816-d30b-439a-b0f3-98f18f798c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566747\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "gzip_captions = []\n",
    "with gzip.open('corpus/multilingual_coco/36langs/coco_en.tsv.gz', 'rt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        gzip_captions.append(line.strip())\n",
    "print(len(gzip_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8927bc1-81e7-4018-a9bf-14fa4e224b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_captions == gzip_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd7e3e-f454-494d-9e28-8b7d3d609b6b",
   "metadata": {},
   "source": [
    "# 3. CC3M\n",
    "```bibtex\r\n",
    "@inproceedings{sharma2018conceptual,\r\n",
    "  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},\r\n",
    "  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},\r\n",
    "  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\r\n",
    "  pages={2556--2565},\r\n",
    "  year={2018}\r\n",
    "}\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b2d8d-9218-41a5-aef2-4d3bc90ac7f0",
   "metadata": {},
   "source": [
    "## 3.1 Official Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c1862-13bc-40d6-8b32-766804fd79de",
   "metadata": {},
   "source": [
    "Place data from: https://ai.google.com/research/ConceptualCaptions/download in this folder\n",
    "\n",
    "- Train_GCC-training.tsv Training Split (3,318,333)\n",
    "\n",
    "- Validation_GCC-1.1.0-Validation.tsv Validation Split (15,840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ff7bb1-3139-44cb-baba-501deb196625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-31 16:20:12--  https://storage.googleapis.com/gcc-data/Train/GCC-training.tsv?_ga=2.191230122.-1896153081.1529438250\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2404:6800:4005:804::201b, 2404:6800:4005:80c::201b, 2404:6800:4005:80a::201b, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:804::201b|:443... failed: Connection timed out.\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:80c::201b|:443... failed: Connection timed out.\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:80a::201b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 564607502 (538M) [application/octet-stream]\n",
      "Saving to: ‘GCC-training.tsv’\n",
      "\n",
      "GCC-training.tsv    100%[===================>] 538.45M  6.33MB/s    in 94s     \n",
      "\n",
      "2024-01-31 16:26:08 (5.75 MB/s) - ‘GCC-training.tsv’ saved [564607502/564607502]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c -O GCC-training.tsv https://storage.googleapis.com/gcc-data/Train/GCC-training.tsv?_ga=2.191230122.-1896153081.1529438250 --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825fe5b2-060c-4e88-adf6-b1cf7b381505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a very typical bus station\thttp://lh6.ggpht.com/-IvRtNLNcG8o/TpFyrudaT6I/AAAAAAAAM6o/_11MuAAKalQ/IMG_3422.JPG?imgmax=800\n",
      "sierra looked stunning in this top and this skirt while performing with person at their former university\thttp://78.media.tumblr.com/3b133294bdc7c7784b781b45eb9af7be/tumblr_nbirmjpEme1tkk0fco1_500.jpg\n",
      "young confused girl standing in front of a wardrobe\thttps://media.gettyimages.com/photos/young-confused-girl-standing-in-front-of-a-wardrobe-picture-id511063329?s=612x612\n",
      "interior design of modern living room with fireplace in a new house\thttps://thumb1.shutterstock.com/display_pic_with_logo/152074/125938838/stock-photo-interior-design-of-modern-living-room-with-fireplace-in-a-new-house-125938838.jpg\n",
      "cybernetic scene isolated on white background .\thttps://thumb1.shutterstock.com/display_pic_with_logo/324673/177023534/stock-photo-cybernetic-scene-isolated-on-white-background-sci-fi-robot-arm-made-of-compound-metallic-as-a-177023534.jpg\n",
      "gangsta rap artist attends sports team vs playoff game in the borough .\thttps://media.gettyimages.com/photos/jayz-attends-the-chicago-bulls-vs-brooklyn-nets-playoff-game-at-the-picture-id167112882\n",
      "the jetty : different types of plants to establish a variety of ecosystems .\thttps://prismpub.com/wp-content/uploads/2016/11/Chicago-Riverwalk_graphic_13.jpg\n",
      "traditional ornamental floral paisley bandanna .\thttps://thumb1.shutterstock.com/display_pic_with_logo/701386/201063638/stock-photo-traditional-ornamental-floral-paisley-bandanna-you-can-use-this-pattern-in-the-design-of-carpet-201063638.jpg\n",
      "# of the sports team skates against sports team during their game .\thttps://media.gettyimages.com/photos/bryan-mccabe-of-the-toronto-maple-leafs-skates-against-the-new-jersey-picture-id73480619?k=6&m=73480619&s=612x612&w=0&h=99aa-OK9NQ_tJCllsuA5vifiFfxD-EW13TNYlg9m9D8=\n",
      "by geographical feature category or in the city - a dome for every environment\thttp://www.robinhoodshow.com/clients/17668/8642054_org.jpg\n"
     ]
    }
   ],
   "source": [
    "!head GCC-training.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bc7a46-41e4-4ce8-93ea-3ee2054b16ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-31 16:27:05--  https://storage.googleapis.com/gcc-data/Validation/GCC-1.1.0-Validation.tsv?_ga=2.141047602.-1896153081.1529438250\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2404:6800:4005:804::201b, 2404:6800:4005:805::201b, 2404:6800:4005:80c::201b, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:804::201b|:443... failed: Connection timed out.\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:805::201b|:443... failed: Connection timed out.\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:80c::201b|:443... failed: Connection timed out.\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4005:80a::201b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2603670 (2.5M) [text/tab-separated-values]\n",
      "Saving to: ‘GCC-1.1.0-Validation.tsv’\n",
      "\n",
      "GCC-1.1.0-Validatio 100%[===================>]   2.48M  2.58MB/s    in 1.0s    \n",
      "\n",
      "2024-01-31 16:33:38 (2.58 MB/s) - ‘GCC-1.1.0-Validation.tsv’ saved [2603670/2603670]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c -O GCC-1.1.0-Validation.tsv https://storage.googleapis.com/gcc-data/Validation/GCC-1.1.0-Validation.tsv?_ga=2.141047602.-1896153081.1529438250 --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4629d3e-14e2-4f16-b5c2-b8b7f98957c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very typical bus station</td>\n",
       "      <td>http://lh6.ggpht.com/-IvRtNLNcG8o/TpFyrudaT6I/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sierra looked stunning in this top and this sk...</td>\n",
       "      <td>http://78.media.tumblr.com/3b133294bdc7c7784b7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young confused girl standing in front of a war...</td>\n",
       "      <td>https://media.gettyimages.com/photos/young-con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interior design of modern living room with fir...</td>\n",
       "      <td>https://thumb1.shutterstock.com/display_pic_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cybernetic scene isolated on white background .</td>\n",
       "      <td>https://thumb1.shutterstock.com/display_pic_wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0                         a very typical bus station   \n",
       "1  sierra looked stunning in this top and this sk...   \n",
       "2  young confused girl standing in front of a war...   \n",
       "3  interior design of modern living room with fir...   \n",
       "4    cybernetic scene isolated on white background .   \n",
       "\n",
       "                                                 url  \n",
       "0  http://lh6.ggpht.com/-IvRtNLNcG8o/TpFyrudaT6I/...  \n",
       "1  http://78.media.tumblr.com/3b133294bdc7c7784b7...  \n",
       "2  https://media.gettyimages.com/photos/young-con...  \n",
       "3  https://thumb1.shutterstock.com/display_pic_wi...  \n",
       "4  https://thumb1.shutterstock.com/display_pic_wi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('GCC-training.tsv', sep='\\t', names=['caption', 'url'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f6c5a7e-7df6-4f65-aaf3-01bdbe1ad8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author : a life in photography -- in pictures</td>\n",
       "      <td>https://i.pinimg.com/736x/66/01/6c/66016c3ba27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an angler fishes river on a snowy day .</td>\n",
       "      <td>http://www.standard.net/image/2015/02/04/800x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>photograph of the sign being repaired by brave...</td>\n",
       "      <td>http://indianapolis-photos.funcityfinder.com/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the player staring intently at a computer scre...</td>\n",
       "      <td>http://www.abc.net.au/news/image/9066492-3x2-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>globes : the green 3d person carrying in hands...</td>\n",
       "      <td>https://www.featurepics.com/StockImage/2009031...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0      author : a life in photography -- in pictures   \n",
       "1            an angler fishes river on a snowy day .   \n",
       "2  photograph of the sign being repaired by brave...   \n",
       "3  the player staring intently at a computer scre...   \n",
       "4  globes : the green 3d person carrying in hands...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://i.pinimg.com/736x/66/01/6c/66016c3ba27...  \n",
       "1  http://www.standard.net/image/2015/02/04/800x_...  \n",
       "2  http://indianapolis-photos.funcityfinder.com/f...  \n",
       "3  http://www.abc.net.au/news/image/9066492-3x2-7...  \n",
       "4  https://www.featurepics.com/StockImage/2009031...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv('GCC-1.1.0-Validation.tsv', sep='\\t', names=['caption', 'url'])\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ea668ee-1b61-4b1e-8e1a-431fd798817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035376 ['2165410_2644318879', '1276069_1690728551', '2377826_3789062313', '3063989_128336495', '2421608_3546761199']\n",
      "12881 ['1323_1011433307', '3333_3463765184', '10458_1850217442', '15135_3012636910', '13395_3305295462']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_root = 'cc3m'\n",
    "existed_train_images = os.listdir(os.path.join(image_root, 'images'))\n",
    "existed_train_lines = set([int(item.split('_')[0]) for item in existed_train_images])\n",
    "print(len(existed_train_images), existed_train_images[:5])\n",
    "      \n",
    "existed_val_images = os.listdir(os.path.join(image_root, 'validation'))\n",
    "existed_val_lines = set([int(item.split('_')[0]) for item in existed_val_images])\n",
    "print(len(existed_val_images), existed_val_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d53594b-81ad-4d89-af04-a7b6d7f4ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3318333/3318333 [05:45<00:00, 9613.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15840/15840 [00:01<00:00, 10089.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import zlib\n",
    "\n",
    "SAVE_PATH = './annotations/cc3m/en'\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "def _file_name(folder_name, line_id, url):\n",
    "    return \"%s/%s_%s\" % (folder_name, line_id, (zlib.crc32(url.encode('utf-8')) & 0xffffffff))\n",
    "\n",
    "for mode, df, existed_lines in zip(['train', 'val'], [train_df, val_df], [existed_train_lines, existed_val_lines]):\n",
    "    folder_name = 'images' if mode == 'train' else 'validation'\n",
    "    json_data = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        if i in existed_lines:\n",
    "            fn = _file_name(folder_name, i, df.iloc[i]['url'])\n",
    "            image_abs_path = os.path.join(image_root, fn)\n",
    "            assert os.path.exists(image_abs_path), image_abs_path\n",
    "            item = dict(\n",
    "                image=fn,\n",
    "                caption=df.iloc[i]['caption'],\n",
    "                image_id=i,\n",
    "            )\n",
    "            json_data.append(item)\n",
    "\n",
    "    with open(os.path.join(SAVE_PATH, f'{mode}.json'), 'w') as wf:\n",
    "        json.dump(json_data, wf)\n",
    "    \n",
    "    if mode == 'val':\n",
    "        gt = {\n",
    "            'annotations': [],\n",
    "            'images': [],\n",
    "        }\n",
    "        caption_id = 0\n",
    "        for item in json_data:\n",
    "            item = dict(\n",
    "                image_id=item['image_id'],\n",
    "                caption=item['caption'],\n",
    "                id=caption_id,\n",
    "            )\n",
    "            caption_id += 1\n",
    "            gt['annotations'].append(item)\n",
    "            gt['images'].append({'id': item['image_id']})\n",
    "                    \n",
    "        with open(os.path.join(SAVE_PATH, f\"{mode}_gt.json\"), 'w') as wf:\n",
    "            json.dump(gt, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01b9b8-04a0-4212-9cb0-6ff8293d0527",
   "metadata": {},
   "source": [
    "## 3.2 Multilingual Corpora\n",
    "\n",
    "Similar to Section 2.2:\n",
    "1. put the train captions (`GCC-training.tsv`) into a `.docx` file line by line (we drop duplicates to save costs)\n",
    "2. get the translated results of the 1st step's file via [Google Translator](https://translate.google.com)\n",
    "3. convert the 2nd step's results to, e.g., `corpus/multilingual_cc3m/36langs/cc3m_en.tsv.gz` and `corpus/multilingual_cc3m/36langs/cc3m_en-zh.tsv.gz`\n",
    "\n",
    "**Note:** After droping duplicates, captions in `GCC-training.tsv` are identical to `corpus/multilingual_cc3m/36langs/cc3m_en.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd0ef87f-9461-4c3b-a044-4377fd602195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAVE_PATH = 'corpus/multilingual_cc3m/36langs'\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c85c917-558b-45de-946a-9b45afe06347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3318333 2348709\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = train_df.drop_duplicates(['caption'])\n",
    "print(len(train_df), len(cleaned_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c22fcd2-8261-4d40-bbc5-0dd8b2e1d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open(os.path.join(SAVE_PATH, 'cc3m_en.tsv.gz'), 'wt', encoding='utf8') as wf:\n",
    "    wf.write('\\n'.join(cleaned_df['caption'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2156367c-2220-4a5d-bfed-f1b71eaa58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "line2idx = {}\n",
    "caption2idx = {}\n",
    "idx = 0\n",
    "for line, caption in enumerate(train_df['caption'].tolist()):\n",
    "    if caption not in caption2idx:\n",
    "        caption2idx[caption] = idx\n",
    "        idx += 1\n",
    "    line2idx[line] = caption2idx[caption]\n",
    "\n",
    "with open(os.path.join(SAVE_PATH, 'line2idx.json'), 'w') as wf:\n",
    "    json.dump(line2idx, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896c5e7-4cfb-4849-b4aa-1939c55a89ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
